---
title: Installing and Configuring Tanzu Service Manager
owner: Platform Engineering (TSMGR Team)
---
<strong><%= modified_date %></strong>

This topic describes how to install and configure
<%= vars.product_full %> (<%= vars.product_short %>) for production using Helm.


## <a id="overview"></a> Overview

Helm is a Kubernetes open source package manager.
You can use a Helm chart to install and configure <%= vars.product_short %>.

To install and configure <%= vars.product_short %> using Helm:

1. [Get <%= vars.product_short %> Resources From <%= vars.product_network %>](#get)

1. [Install the <%= vars.product_short %> CLI](#cli)

1. [Replicate <%= vars.product_short %> Images](#replicate-images)

1. [(Recommended) Configure Service Mesh](#service-mesh)

1. [Configure the <%= vars.product_short %> Helm Chart](#configure)

1. [Install the <%= vars.product_short %> Helm Chart](#install)

1. [(Recommended) Configure Security](#security)

1. [(Optional) Install Prometheus](#prometheus)

1. [Next Steps](#next-steps)


## <a id="prereq"></a>Prerequisites

Before you install <%= vars.product_short %> using Helm, you must have:

* **Helm 3 CLI (v3.2.4 or later):** For information about installing the Helm CLI,
see the [Helm documentation](https://helm.sh/docs/intro/install/).

* **Docker CLI:** For information about installing Docker,
  see the [Docker documentation](https://docs.docker.com/get-docker/).

* **<%= vars.app_runtime_abbr %> Deployment:** A running <%= vars.app_runtime_abbr %> deployment.

* **Kubernetes Cluster:** A running Kubernetes cluster.
  <%= vars.product_short %> supports <%= vars.k8s_runtime_full %> clusters.
  For supported cluster versions, see the [Product Snapshot](index.html#snapshot).
  For information about <%= vars.k8s_runtime_abbr %>, see
  [<%= vars.k8s_runtime_full %>](https://docs.pivotal.io/pks/index.html).

* **Kubernetes CLI:** For information about installing kubectl,
  see the [Kubernetes documentation](https://kubernetes.io/docs/tasks/tools/install-kubectl/).

* **S3 Compatible Storage:** <%= vars.product_short %> requires a S3-compatible bucket to store
offered charts and the chart cache.
For more information, see [Configuring External Storage](./storage.html).

* **Private Container Image Registry:** You need this to manage container images in air-gapped
environments.
VMware recommends using a registry in production deployments. You can use a registry such as
[Harbor](https://network.pivotal.io/products/harbor-container-registry).

* **Install the Ingress controller on the cluster where you want to install
<%= vars.product_short %>:** You must also reserve a subdomain for <%= vars.product_short %>
in your DNS.
For information about Ingress, see the
[Kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/).

* **Cloud Foundry CLI (cf CLI):** To download the cf CLI,
  see [Cloud Foundry CLI](https://github.com/cloudfoundry/cli) in GitHub.
  Although, the cf CLI is not required for the procedures in this topic,
  it is required to give developers access to services.
  See [Using Services with Tanzu Service Manager](using.html).

## <a id='get'></a> Get <%= vars.product_short %> Resources From <%= vars.product_network %>

To get the resources needed from <%= vars.product_network %> to install <%= vars.product_short %>:

1. Log in and navigate to **<%= vars.product_full %> (<%= vars.product_short %>)** in
[<%= vars.product_network %>](https://network.pivotal.io/products/tanzu-service-manager).

1. Get the following resources:
    + **The <%= vars.product_short %> Command Line Interface (CLI):** Click **CLIs** and download
    the CLI for your operating system.
    + **Docker `pull` commands:** Click **Artifact References** and record the `docker pull`
    commands for the **broker**, **daemon**, and **chartmuseum**.
    + **Helm chart TGZ file:** Click **<%= vars.product_cli %>-VERSION-NUMBER.tgz** and download the
    Helm chart
    for <%= vars.product_short %>.
    + **values-production.yaml file:** Download the `values-production.yaml` override configuration
    file.


## <a id='cli'></a>  Install the <%= vars.product_short %> CLI

To install the <%= vars.product_short %> Command Line Interface (CLI):

1. Rename the downloaded <%= vars.product_short %> CLI file as `<%= vars.product_cli %>`.

1. Make the <%= vars.product_short %> binary act as an executable file by running:

    ```bash
    chmod +x <%= vars.product_cli %>
    ```

1. Move the binary file into your `PATH` by running:

    ```bash
    mv <%= vars.product_cli %> /usr/local/bin/<%= vars.product_cli %>
    ```

1. Ensure <%= vars.product_short %> CLI is properly working:

    ```bash
    <%= vars.product_cli %> version
    ```


## <a id='replicate-images'></a> Replicate <%= vars.product_short %> Images

To replicate your <%= vars.product_short %> images to a private container image registry:

1. Relocate the images to your local machine:
    Run the `docker pull` commands recorded in [Get <%= vars.product_short %> Resources From <%= vars.product_network %>](#get) above,
    to pull the images. The registry credentials are the same as your <%= vars.product_network %> credentials.

1. Tag the images for your registry by running these commands:

    ```
    docker tag registry.pivotal.io/tanzu-service-manager/broker:VERSION-NUMBER \
     REGISTRY/tanzu-service-manager/broker:VERSION-NUMBER
    ```
    ```
    docker tag registry.pivotal.io/tanzu-service-manager/daemon:VERSION-NUMBER \
     REGISTRY/tanzu-service-manager/daemon:VERSION-NUMBER
    ```
    ```
    docker tag registry.pivotal.io/tanzu-service-manager/chartmuseum:CHARTMUSEUM-VERSION-NUMBER \
     REGISTRY/tanzu-service-manager/chartmuseum:CHARTMUSEUM-VERSION-NUMBER
    ```
    Where:
    + `VERSION-NUMBER` is the <%= vars.product_short %> release version number.
      This value is in the `docker pull` command that you recorded in
      [Get <%= vars.product_short %> Resources From <%= vars.product_network %>](#get) above.
    + `REGISTRY` is the private container image registry you configured for <%= vars.product_short %>.
    + `CHARTMUSEUM-VERSION-NUMBER` is the ChartMuseum version number.
      This value is in the `docker pull` command that you recorded in
      [Get <%= vars.product_short %> Resources From <%= vars.product_network %>](#get) above.

    For example:

    <pre class="terminal">
    $ docker tag registry.pivotal.io/tanzu-service-manager/broker:1.0.1 \
    privateregistry.domain.com/tanzu-service-manager/broker:1.0.1

    $ docker tag registry.pivotal.io/tanzu-service-manager/daemon:1.0.1 \
    privateregistry.domain.com/tanzu-service-manager/daemon:1.0.1

    $ docker tag registry.pivotal.io/tanzu-service-manager/chartmuseum:1.0.1 \
    privateregistry.domain.com/tanzu-service-manager/chartmuseum:1.0.1
    </pre>

    Alternatively, if you downloaded the TGZ files, you can verify the versions by running the
    `docker images` command and looking at the `TAG` column for each referred image.

1. Create the `tanzu-service-manager` project in your registry.

1. Push the images to your registry by running these commands:

    ```
    docker push REGISTRY/tanzu-service-manager/broker:VERSION-NUMBER
    ```
    ```
    docker push REGISTRY/tanzu-service-manager/daemon:VERSION-NUMBER
    ```
    ```
    docker push REGISTRY/tanzu-service-manager/chartmuseum:CHARTMUSEUM-VERSION-NUMBER
    ```
    Where `REGISTRY` is the private container image registry path.

    For example:

    <pre class="terminal">
    $ docker push privateregistry.domain.com/tanzu-service-manager/broker:1.0.1
    $ docker push privateregistry.domain.com/tanzu-service-manager/daemon:1.0.1
    $ docker push privateregistry.domain.com/tanzu-service-manager/chartmuseum:1.0.1
    </pre>

## <a id="service-mesh"></a> (Recommended) Configure Service Mesh

You can secure traffic between <%= vars.product_short %> components by using a service mesh, such as
[Istio](https://istio.io/latest/docs/concepts/what-is-istio/).

To configure an Istio service mesh:

1. Install Istio on your Kubernetes cluster by following the
[Istio documentation](https://istio.io/latest/docs/setup/install/).
Follow the steps in the installation guide that best meets your needs.

1. Inject Istio into the namespace where <%= vars.product_short %> will be deployed by running:

    ```
    kubectl create ns <%= vars.product_short %>-NAMESPACE
    ```
    ```
    kubectl label namespace <%= vars.product_short %>-NAMESPACE istio-injection=enabled
    ```
    Where `<%= vars.product_short %>-NAMESPACE` is a name you choose for the <%= vars.product_short %>
    dedicated namespace.


## <a id='configure'></a> Configure the <%= vars.product_short %> Helm Chart

<p class="note">
  <strong>Note:</strong> To see a detailed description of each value and its default, run:
  <code>helm show values <%= vars.product_cli %>-VERSION-NUMBER.tgz</code>.
</p>

To configure the <%= vars.product_short %> Helm chart, edit the `values-production.yaml` file:

1. Add the credentials for the registry where you replicated the <%= vars.product_short %> images:

    ```yaml
    imageCredentialsFor<%= vars.product_short %>Images:
     registry: REGISTRY
     username: REGISTRY-USERNAME
     password: REGISTRY-PASSWORD
    ```
    Where:
    + `REGISTRY` is the registry you configured for installation images,
    for example, `privateregistry.domain.com/tanzu-service-manager`.
    + `REGISTRY-USERNAME` is the username for the registry.
    + `REGISTRY-PASSWORD` is the password for the registry.

    <%= vars.product_short %> uses this registry for <%= vars.product_short %> installation Docker
    images.
    A new secret named <code>registrySecretName</code> of type <code>dockerconfigjson</code>
    is created with these credentials.

1. Add the credentials for the registry where the service instance images come from.

    Service instance refers to the Helm chart files that <%= vars.product_short %> manages as
    services, such as mysql, postgresql, and etc-operator.

    ```yaml
    imageCredentialsForServiceInstances:
     registry: REGISTRY-INSTANCES
     username: REGISTRY-INSTANCES-USERNAME
     password: REGISTRY-INSTANCES-PASSWORD
    ```
    Where:
    + `REGISTRY-INSTANCES` is the registry you configured to offer images,
       for example, `anotherregistry.domain.com/project`.
    + `REGISTRY-INSTANCES-USERNAME` is the username for the registry. This user can have read-only
    access.
    + `REGISTRY-INSTANCES-PASSWORD` is the password for the registry.

    <%= vars.product_short %> uses this registry as the backing registry for the services that
    <%= vars.product_short %> deploys.
    <%= vars.product_short %> modifies the Helm charts that you offer to point to images in the
    registry.

    <p class="note">
      <strong>Note:</strong> Although this configuration is optional, VMware recommends using a
      private container registry in production.
    </p>

1. Define values for your registry by configuring the repository attributes:

    ```yaml
    broker:
     image:
       repository: REGISTRY/tanzu-service-manager/broker
    daemon:
     image:
       repository: REGISTRY/tanzu-service-manager/daemon
    chartmuseum:
     image:
       repository: REGISTRY/tanzu-service-manager/chartmuseum
    ```
    Where `REGISTRY` is your private container image registry, for example,
    `privateregistry.domain.com`.

1. Define a secure password to authenticate your services by configuring the password attributes:

    ```yaml
    broker:
     password: BROKER-PASSWORD
    chartmuseum:
     env:
       open:
         BASIC_AUTH_PASS: CHARTMUSEUM-PASSWORD
    ```
    Where:
    + `BROKER-PASSWORD` is a secure password for the <%= vars.product_short %> broker.
    + `CHARTMUSEUM-PASSWORD` is a secure password for ChartMuseum.

1. <a name='create-uaa-client'></a> Create a User Account and Authentication (UAA) client for
<%= vars.product_short %> to use to register the broker and populate the catalog:

    ```bash
    uaac target uaa.SYSTEM-DOMAIN
    uaac token client get admin -s UAA-ADMIN-CLIENT-SECRET
    uaac client add CLIENT-ID -s CLIENT-SECRET \
      --authorized_grant_types client_credentials,refresh_token \
      --scope cloud_controller.read,cloud_controller.write \
      --authorities cloud_controller.admin
    ```
    Where:
    + `SYSTEM-DOMAIN` is the system domain for <%= vars.app_runtime_abbr %>.
    + `UAA-ADMIN-CLIENT-SECRET` is the UAA Admin Client Credentials for <%= vars.app_runtime_abbr %>.
    + `CLIENT-ID` is the name of the client.
    + `CLIENT-SECRET` is the secret of the client.

    For information about UAA clients,
    see [User Account and Authentication (UAA) Server](https://docs.cloudfoundry.org/concepts/architecture/uaa.html)
    in the Cloud Foundry documentation.

1. Get the annotation information required by your Ingress controller.
   Use the appropriate section below:
  + **If you are using an automated certificate management provider such as cert-manager:**
    Follow the procedures to install and configure the prerequisites for the certificate
    management provider that you are using.
    <br>For example, the prerequisite for `cert-manager` is to set up an `Issuer` on the
    cluster.
    For more information, see the [cert-manager documentation](https://cert-manager.io/docs/configuration/).<br><br>
  + **If you are using your own TLS certificates:** Create secrets with TLS certificate data.

        ```
        kubectl create secret tls daemon-cert --key DAEMON-KEY-FILE --cert DAEMON-CERT-FILE -n  NAMESPACE
        ```
        ```
        kubectl create secret tls broker-cert --key BROKER-KEY-FILE --cert BROKER-CERT-FILE -n  NAMESPACE
        ```
        Where:
        + `NAMESPACE` is the namespace where <%= vars.product_short %> will be installed or,
          if you use an Istio Ingress controller,
          `NAMESPACE` is the same namespace as the istio-ingressgateway deployment,
          typically `istio-system`.
        + `DAEMON-KEY-FILE` and `DAEMON-CERT-FILE` are the paths to your TLS private key and certificate for the daemon.
        + `BROKER-KEY-FILE` and `BROKER-CERT-FILE` are the paths to your TLS private key and certificate for the broker.

1.  If you are using your own TLS certificates, follow the steps in [Setting Trusted Certificates]
    (https://docs.pivotal.io/ops-manager/trusted-certificates.html)
    to ensure that  <%= vars.ops_manager %> and <%= vars.app_runtime_abbr %> trust the certificate.

1. Add the following Ingress section to your `<%= vars.product_cli %>/values.yml` file:

    ```yaml
    ingress:
     enabled: true
     hosts:
     - name: INGRESS-DOMAIN
       path: INGRESS-PATH
     annotations:
       ANNOTATION-KEY: ANNOTATION-VALUE
     tls:
     - secretName: daemon-cert
       hosts:
         - daemon.INGRESS-DOMAIN
     - secretName: broker-cert
       hosts:
         - broker.INGRESS-DOMAIN
    ```
    Where:
    + `INGRESS-DOMAIN` is the name of your provisioned domain.
    + `INGRESS-PATH` is the path expression to match all paths for your particular ingress
    controller.<br>
    Istio Ingress controller is set to `"/*"`.<br>
    NGINX Ingress controller is set to `"/"`.<br>
    Contour Ingress controller is set to `"/"`.
    + `ANNOTATION-KEY` and `ANNOTATION-VALUE` is the annotation your Ingress controller requires.

    These values depend on the Ingress controller and certificate management option you use.
    For example, see the annotations for Istio Ingress controller and cert-manager:

    ```
    annotations:
        kubernetes.io/ingress.class: istio
        cert-manager.io/issuer: "letsencrypt-prod"
    ```

    <p class="note">
      <strong>Note:</strong> Implementation details vary by Ingress controller.
      For more detailed usage instructions, see the documentation for your chosen Ingress
      controller.
    </p>

1. Configure the Cloud Foundry environment details:

    ```yaml
    cf:
     apiAddress: https://api.SYSTEM-DOMAIN
     client: CLIENT-ID
     clientSecret: CLIENT-SECRET
     brokerName: <%= vars.product_cli %>
     brokerUrl: https://broker.INGRESS-DOMAIN
    ```
    Where:
    + `SYSTEM-DOMAIN` is the system domain for <%= vars.app_runtime_abbr %>.
    + `CLIENT-ID` is the client ID created in the step
    [Create a User Account and Authentication client](#create-uaa-client) above.
    Alternatively, you can use an existing client ID for a <%= vars.app_runtime_abbr %>
    account with `cloud_controller.admin` permissions.
    + `CLIENT-SECRET` is the client secret for the <%= vars.app_runtime_abbr %> account.
    + `INGRESS-DOMAIN` is the name of your provisioned domain.

    <p class="note">
      <strong>Note:</strong> Alternatively, you can use the Cloud Foundry username and password,
      but this is discouraged for production.
      When using the username and password, replace <code>client:</code> with <code>username:</code>
      and <code>clientSecret:</code> with <code>password:</code>.
    </p>

1. Verify the Cloud Foundry `apiAddress` by running the `cf target` command.

1.  Add the credentials for your S3-compatible bucket using the template below:

    ```yaml
    chartmuseum:
      env:
        open:
          STORAGE_AMAZON_BUCKET: BUCKET-NAME
          STORAGE_AMAZON_ENDPOINT: ENDPOINT
        secret:
          AWS_ACCESS_KEY_ID: ACCESS-KEY
          AWS_SECRET_ACCESS_KEY: SECRET
    ```
    Where:
    + `BUCKET-NAME` is your S3 bucket name.
    + `ENDPOINT` is your S3 endpoint. For example, in Google Cloud Platform (GCP) it is
    `storage.googleapis.com`.
    + `ACCESS-KEY` is your S3 access key ID.
    + `SECRET` is your S3 secret access key.

    The above credentials are for AWS.
    Depending on your IaaS, the credentials might not be a comprehensive list of the keys you need.
    For example, if you are not using using the default region, you might need to add the
    `STORAGE_AMAZON_REGION`:

    ```
    chartmuseum:
      env:
        open:
          STORAGE_AMAZON_REGION: us-east-1
    ```
    For more information about configurations, see
    <a href="https://github.com/helm/charts/tree/master/stable/chartmuseum">ChartMuseum Helm Chart</a> in GitHub.

1. Save the `values-production.yaml` file.


## <a id='install'></a> Install the <%= vars.product_short %> Helm Chart

To install the <%= vars.product_short %> Helm chart:

1. From the root level of the chart, install the <%= vars.product_short %> Helm chart by running
these commands:

    ```bash
    kubectl create ns <%= vars.product_short %>-NAMESPACE
    ```
    ```
    helm install RELEASE-NAME <%= vars.product_cli %>-VERSION-NUMBER.tgz  -n <%= vars.product_short %>-NAMESPACE --wait -f values-production.yaml
    ```
    Where:
    + `<%= vars.product_short %>-NAMESPACE` is a name you choose for the <%= vars.product_short %>
    dedicated namespace.
    + `RELEASE-NAME` is a name you choose for the release.
       Helm release names must begin and end with lowercase alphanumeric characters
       and can only contain lowercase alphanumeric characters and hyphens.
    + `<%= vars.product_cli %>-VERSION-NUMBER.tgz` is the <%= vars.product_short %> Helm chart file
    you downloaded earlier.


## <a id="security"></a> (Recommended) Configure Security

VMware recommends configuring security on your Kubernetes cluster for <%= vars.product_short %>.

To configure security:

1. Secure <%= vars.product_short %> secrets by using a secret provider. See
[Encrypting Secret Data at Rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/)
in the Kubernetes documentation.
1. Enable network policies on the cluster to secure traffic between services.
See [Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/) in
the Kubernetes documentation.
Some settings can vary between clouds.
For example, in GKE, network policies are not enabled by default.
For more information, see your cloud-specific documentation.


## <a id="prometheus"></a> (Optional) Install Prometheus

You can view metrics for <%= vars.product_short %> if you have Prometheus running in the cluster.
You must install Prometheus in each cluster that you want to view metrics for.

To install Prometheus to a cluster:

1. Install the Prometheus Helm chart by running these commands:

    ```bash
    kubectl create ns prometheus

    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

    helm install my-prometheus prometheus-community/prometheus -n prometheus
    ```

1. Create a Kubernetes port forward to your local host by running these commands:

    ```
    export POD_NAME=$(kubectl get pods --namespace prometheus -l "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}")

    kubectl --namespace prometheus port-forward $POD_NAME 9090
    ```

1. Access the Prometheus UI in your web browser at [http://localhost:9090](http://localhost:9090).

1. To view metrics for <%= vars.product_short %>, type
`{app_kubernetes_io_name=~".*-<%= vars.product_cli %>"}` in the expression box and click **Execute**.


## <a id="next-steps"></a> Next Steps

After installing and configuring <%= vars.product_short %>, you can start using
<%= vars.product_short %>.
For information, see [Using <%= vars.product_full %>](using.html).
